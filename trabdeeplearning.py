# -*- coding: utf-8 -*-
"""trabDeepLearning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lEwjAJFYYM1p2p6wvoYCGvqXiC5v78Sz
"""

import pandas as pd
import re
import string
import numpy as np
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from keras.models import Sequential
from keras.layers import Embedding, GlobalAveragePooling1D, Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.callbacks import EarlyStopping

import seaborn as sns
import matplotlib.pyplot as plt

dados = pd.read_csv("hf://datasets/TLeonidas/twitter-hate-speech-en-240ksamples/recombined_data.csv")
dados.head()

dados.shape

dados.groupby(["labels"]).size()

def limpar_mencoes(tweet):
    return re.sub(r'@\w+', '', tweet)

dados['tweet_limpo'] = dados['tweet'].apply(limpar_mencoes)
dados.head()

dados['label_binaria'] = dados['labels'].apply(lambda x: 1 if x == 'Offensive or Hate Speech' else 0)
dados.head()

dados = dados.drop(['tweet', 'labels'], axis=1)
dados.head()

def limpar_texto(texto):
    texto = re.sub(r'^[^\w]*RT\s*:?[\s]*', '', texto, flags=re.IGNORECASE)
    texto = re.sub(r'http\S+', '', texto)
    texto = re.sub(r'[^A-Za-zÀ-ÖØ-öø-ÿ\s]', '', texto)
    texto = texto.lower()
    return texto.strip()

dados['tweet_limpo'] = dados['tweet_limpo'].apply(limpar_texto)
dados.head()

print(dados['label_binaria'].value_counts(normalize=True))

stop = ENGLISH_STOP_WORDS

def remover_stopwords(texto):
    palavras = texto.split()
    palavras_filtradas = [p for p in palavras if p not in stop and p not in string.punctuation]
    return ' '.join(palavras_filtradas)
dados['tweet_limpo'] = dados['tweet_limpo'].apply(remover_stopwords)

dados.head()

tamanho_vocab = 10000
tokenizer = Tokenizer(num_words=tamanho_vocab, oov_token="<OOV>")
tokenizer.fit_on_texts(dados['tweet_limpo'])

sequences = tokenizer.texts_to_sequences(dados['tweet_limpo'])

padded_sequences = pad_sequences(sequences, padding='post', truncating='post', maxlen=50)

previsores = padded_sequences
classe = dados.label_binaria

x_treinamento, x_teste, y_treinamento, y_teste = train_test_split(previsores, classe, test_size=0.3, random_state=42)

modelo = Sequential()
modelo.add(Embedding(input_dim=tamanho_vocab, output_dim=32, input_length=50))
modelo.add(GlobalAveragePooling1D())
modelo.add(Dense(units=32, activation='relu'))
modelo.add(Dropout(0.2))
modelo.add(Dense(units=16, activation='relu'))
modelo.add(Dropout(0.1))
modelo.add(Dense(units=1, activation='sigmoid'))

modelo.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

modelo.build(input_shape=(None, 50))
modelo.summary()

treino = modelo.fit(x_treinamento, y_treinamento, epochs=100, validation_data=(x_teste, y_teste), callbacks=[early_stop])

previsoes = modelo.predict(x_teste)
previsoes

y_pred = (previsoes > 0.5).astype(int)

acuracia = accuracy_score(y_teste, y_pred)
acuracia

confusao = confusion_matrix(y_teste, y_pred)
print("Matriz de Confusão:")
print(confusao)

print("\nRelatório de Classificação:")
print(classification_report(y_teste, y_pred))

plt.figure(figsize=(8,6))
sns.heatmap(confusao, annot=True, cmap="Greens", cbar=False, fmt="d",
xticklabels=["Não é hate", "Hate"],
yticklabels=["Não é hate", "Hate"])

plt.title("Matriz de confusão")
plt.xlabel("Previsão")
plt.ylabel("Real")
plt.show();

frase_teste = input("Digite um comentário: ")
frase_limpa = limpar_texto(frase_teste)
frase_limpa = remover_stopwords(frase_limpa)

seq = tokenizer.texts_to_sequences([frase_limpa])
seq_padded = pad_sequences(seq, padding='post', truncating='post', maxlen=50)

prob = modelo.predict(seq_padded)[0][0]

if prob > 0.5:
    print(f"✅ Discurso de ódio detectado (probabilidade: {prob:.2f})")
else:
    print(f"❌ Sem discurso de ódio detectado (probabilidade: {prob:.2f})")