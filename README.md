Projeto de Deep Learning: Detec√ß√£o de Discurso de √ìdio
Este projeto visa desenvolver um modelo de Deep Learning para identificar discurso de √≥dio em coment√°rios de redes sociais na l√≠ngua inglesa, utilizando Processamento de Linguagem Natural (NLP). O objetivo √© contribuir para a modera√ß√£o de conte√∫do online e promover ambientes mais seguros.

üìä Dataset
O projeto utilizou o dataset twitter-hate-speech-en-240ksamples da Hugging Face, contendo cerca de 240 mil coment√°rios do Twitter categorizados como hate speech, Neutral or Ambiguous e non-hate speech.

‚ú® Pr√©-processamento
As etapas de pr√©-processamento inclu√≠ram:
-Remo√ß√£o de men√ß√µes de usu√°rios, links, pontua√ß√µes, emojis e s√≠mbolos.
-Padroniza√ß√£o para letras min√∫sculas e remo√ß√£o de stopwords.
-Classifica√ß√£o bin√°ria (0 para aus√™ncia de √≥dio, 1 para presen√ßa).
-Tokeniza√ß√£o e padroniza√ß√£o das sequ√™ncias para 50 tokens.
-Divis√£o dos dados em 70% treino e 30% teste.

üß† Modelo de Deep Learning
O modelo √© uma rede neural sequencial constru√≠da com Keras, composta por:
-Camada de Embedding: Transforma palavras em vetores densos (32 dimens√µes).
-Camada GlobalAveragePooling1D: Reduz a dimensionalidade.
-Camadas Densa (Dense): Introduzem n√£o linearidade (32 e 16 neur√¥nios com ativa√ß√£o ReLU).
-Camadas Dropout: Para regulariza√ß√£o e preven√ß√£o de overfitting (taxas de 0.2 e 0.1).
-Camada de Sa√≠da: Um neur√¥nio com ativa√ß√£o sigmoid para classifica√ß√£o bin√°ria.
O treinamento utilizou binary_crossentropy, otimizador adam e accuracy como m√©trica. Foi implementado Early Stopping para evitar overfitting.

üìä Resultados
O modelo final obteve uma acur√°cia geral de 0.8158 (quase 82%).
Acertos (Sem √≥dio): 33.066.
Acertos (Com √≥dio): 26.346.
Precis√£o (Classe 1): 83%.
Recall (Classe 1): 77%.
F1-score (Classe 1): 80%.
